{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library to interact with the OS\n",
    "import os\n",
    "\n",
    "# Libraries for reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "PROJECT_DIR = os.path.join(os.path.dirname('preprocessing.ipynb'), os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Data</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Local</th>\n",
       "      <th>Industry Sector</th>\n",
       "      <th>Accident Level</th>\n",
       "      <th>Potential Accident Level</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Employee or Third Party</th>\n",
       "      <th>Critical Risk</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_01</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Pressed</td>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Country_02</td>\n",
       "      <td>Local_02</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employee</td>\n",
       "      <td>Pressurized Systems</td>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_03</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>III</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party (Remote)</td>\n",
       "      <td>Manual Tools</td>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>IV</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Data   Countries     Local Industry Sector Accident Level  \\\n",
       "0           0 2016-01-01  Country_01  Local_01          Mining              I   \n",
       "1           1 2016-01-02  Country_02  Local_02          Mining              I   \n",
       "2           2 2016-01-06  Country_01  Local_03          Mining              I   \n",
       "3           3 2016-01-08  Country_01  Local_04          Mining              I   \n",
       "4           4 2016-01-10  Country_01  Local_04          Mining             IV   \n",
       "\n",
       "  Potential Accident Level Genre Employee or Third Party        Critical Risk  \\\n",
       "0                       IV  Male             Third Party              Pressed   \n",
       "1                       IV  Male                Employee  Pressurized Systems   \n",
       "2                      III  Male    Third Party (Remote)         Manual Tools   \n",
       "3                        I  Male             Third Party               Others   \n",
       "4                       IV  Male             Third Party               Others   \n",
       "\n",
       "                                         Description  \n",
       "0  While removing the drill rod of the Jumbo 08 f...  \n",
       "1  During the activation of a sodium sulphide pum...  \n",
       "2  In the sub-station MILPO located at level +170...  \n",
       "3  Being 9:45 am. approximately in the Nv. 1880 C...  \n",
       "4  Approximately at 11:45 a.m. in circumstances t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df = pd.read_excel('Health_database.xlsx')\n",
    "is_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Data', 'Countries', 'Local', 'Industry Sector',\n",
       "       'Accident Level', 'Potential Accident Level', 'Genre',\n",
       "       'Employee or Third Party', 'Critical Risk', 'Description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the index column\n",
    "is_df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicates\n",
    "is_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "is_df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Data', 'Countries', 'Genre' columns in Data frame\n",
    "is_df.rename(columns={'Data':'Date', 'Countries':'Country', 'Genre':'Gender'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating Attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Date                      418 non-null    datetime64[ns]\n",
      " 1   Country                   418 non-null    object        \n",
      " 2   Local                     418 non-null    object        \n",
      " 3   Industry Sector           418 non-null    object        \n",
      " 4   Accident Level            418 non-null    int64         \n",
      " 5   Potential Accident Level  418 non-null    int64         \n",
      " 6   Gender                    418 non-null    int64         \n",
      " 7   Employee or Third Party   418 non-null    object        \n",
      " 8   Critical Risk             418 non-null    object        \n",
      " 9   Description               418 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(6)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "is_df['Gender'] = is_df['Gender'].apply(lambda x: {'Male': 0, 'Female': 1}[x])\n",
    "is_df['Accident Level'] = is_df['Accident Level'].apply(lambda x: {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5}[x])\n",
    "is_df['Potential Accident Level'] = is_df['Potential Accident Level'].apply(lambda x: {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6}[x])\n",
    "\n",
    "is_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping datetime info\n",
    "is_df.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "is_df = pd.get_dummies(is_df, columns=['Country', 'Local', 'Industry Sector', 'Employee or Third Party', 'Critical Risk'], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                                   Non-Null Count  Dtype \n",
      "---  ------                                                   --------------  ----- \n",
      " 0   Accident Level                                           418 non-null    int64 \n",
      " 1   Potential Accident Level                                 418 non-null    int64 \n",
      " 2   Gender                                                   418 non-null    int64 \n",
      " 3   Description                                              418 non-null    object\n",
      " 4   Country_Country_01                                       418 non-null    int64 \n",
      " 5   Country_Country_02                                       418 non-null    int64 \n",
      " 6   Country_Country_03                                       418 non-null    int64 \n",
      " 7   Local_Local_01                                           418 non-null    int64 \n",
      " 8   Local_Local_02                                           418 non-null    int64 \n",
      " 9   Local_Local_03                                           418 non-null    int64 \n",
      " 10  Local_Local_04                                           418 non-null    int64 \n",
      " 11  Local_Local_05                                           418 non-null    int64 \n",
      " 12  Local_Local_06                                           418 non-null    int64 \n",
      " 13  Local_Local_07                                           418 non-null    int64 \n",
      " 14  Local_Local_08                                           418 non-null    int64 \n",
      " 15  Local_Local_09                                           418 non-null    int64 \n",
      " 16  Local_Local_10                                           418 non-null    int64 \n",
      " 17  Local_Local_11                                           418 non-null    int64 \n",
      " 18  Local_Local_12                                           418 non-null    int64 \n",
      " 19  Industry Sector_Metals                                   418 non-null    int64 \n",
      " 20  Industry Sector_Mining                                   418 non-null    int64 \n",
      " 21  Industry Sector_Others                                   418 non-null    int64 \n",
      " 22  Employee or Third Party_Employee                         418 non-null    int64 \n",
      " 23  Employee or Third Party_Third Party                      418 non-null    int64 \n",
      " 24  Employee or Third Party_Third Party (Remote)             418 non-null    int64 \n",
      " 25  Critical Risk_\n",
      "Not applicable                            418 non-null    int64 \n",
      " 26  Critical Risk_Bees                                       418 non-null    int64 \n",
      " 27  Critical Risk_Blocking and isolation of energies         418 non-null    int64 \n",
      " 28  Critical Risk_Burn                                       418 non-null    int64 \n",
      " 29  Critical Risk_Chemical substances                        418 non-null    int64 \n",
      " 30  Critical Risk_Confined space                             418 non-null    int64 \n",
      " 31  Critical Risk_Cut                                        418 non-null    int64 \n",
      " 32  Critical Risk_Electrical Shock                           418 non-null    int64 \n",
      " 33  Critical Risk_Electrical installation                    418 non-null    int64 \n",
      " 34  Critical Risk_Fall                                       418 non-null    int64 \n",
      " 35  Critical Risk_Fall prevention                            418 non-null    int64 \n",
      " 36  Critical Risk_Fall prevention (same level)               418 non-null    int64 \n",
      " 37  Critical Risk_Individual protection equipment            418 non-null    int64 \n",
      " 38  Critical Risk_Liquid Metal                               418 non-null    int64 \n",
      " 39  Critical Risk_Machine Protection                         418 non-null    int64 \n",
      " 40  Critical Risk_Manual Tools                               418 non-null    int64 \n",
      " 41  Critical Risk_Others                                     418 non-null    int64 \n",
      " 42  Critical Risk_Plates                                     418 non-null    int64 \n",
      " 43  Critical Risk_Poll                                       418 non-null    int64 \n",
      " 44  Critical Risk_Power lock                                 418 non-null    int64 \n",
      " 45  Critical Risk_Pressed                                    418 non-null    int64 \n",
      " 46  Critical Risk_Pressurized Systems                        418 non-null    int64 \n",
      " 47  Critical Risk_Pressurized Systems / Chemical Substances  418 non-null    int64 \n",
      " 48  Critical Risk_Projection                                 418 non-null    int64 \n",
      " 49  Critical Risk_Projection of fragments                    418 non-null    int64 \n",
      " 50  Critical Risk_Projection/Burning                         418 non-null    int64 \n",
      " 51  Critical Risk_Projection/Choco                           418 non-null    int64 \n",
      " 52  Critical Risk_Projection/Manual Tools                    418 non-null    int64 \n",
      " 53  Critical Risk_Suspended Loads                            418 non-null    int64 \n",
      " 54  Critical Risk_Traffic                                    418 non-null    int64 \n",
      " 55  Critical Risk_Vehicles and Mobile Equipment              418 non-null    int64 \n",
      " 56  Critical Risk_Venomous Animals                           418 non-null    int64 \n",
      " 57  Critical Risk_remains of choco                           418 non-null    int64 \n",
      "dtypes: int64(57), object(1)\n",
      "memory usage: 189.5+ KB\n"
     ]
    }
   ],
   "source": [
    "is_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Level</th>\n",
       "      <th>Potential Accident Level</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Description</th>\n",
       "      <th>Country_Country_01</th>\n",
       "      <th>Country_Country_02</th>\n",
       "      <th>Country_Country_03</th>\n",
       "      <th>Local_Local_01</th>\n",
       "      <th>Local_Local_02</th>\n",
       "      <th>Local_Local_03</th>\n",
       "      <th>...</th>\n",
       "      <th>Critical Risk_Projection</th>\n",
       "      <th>Critical Risk_Projection of fragments</th>\n",
       "      <th>Critical Risk_Projection/Burning</th>\n",
       "      <th>Critical Risk_Projection/Choco</th>\n",
       "      <th>Critical Risk_Projection/Manual Tools</th>\n",
       "      <th>Critical Risk_Suspended Loads</th>\n",
       "      <th>Critical Risk_Traffic</th>\n",
       "      <th>Critical Risk_Vehicles and Mobile Equipment</th>\n",
       "      <th>Critical Risk_Venomous Animals</th>\n",
       "      <th>Critical Risk_remains of choco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accident Level  Potential Accident Level  Gender  \\\n",
       "0               1                         4       0   \n",
       "1               1                         4       0   \n",
       "\n",
       "                                         Description  Country_Country_01  \\\n",
       "0  While removing the drill rod of the Jumbo 08 f...                   1   \n",
       "1  During the activation of a sodium sulphide pum...                   0   \n",
       "\n",
       "   Country_Country_02  Country_Country_03  Local_Local_01  Local_Local_02  \\\n",
       "0                   0                   0               1               0   \n",
       "1                   1                   0               0               1   \n",
       "\n",
       "   Local_Local_03  ...  Critical Risk_Projection  \\\n",
       "0               0  ...                         0   \n",
       "1               0  ...                         0   \n",
       "\n",
       "   Critical Risk_Projection of fragments  Critical Risk_Projection/Burning  \\\n",
       "0                                      0                                 0   \n",
       "1                                      0                                 0   \n",
       "\n",
       "   Critical Risk_Projection/Choco  Critical Risk_Projection/Manual Tools  \\\n",
       "0                               0                                      0   \n",
       "1                               0                                      0   \n",
       "\n",
       "   Critical Risk_Suspended Loads  Critical Risk_Traffic  \\\n",
       "0                              0                      0   \n",
       "1                              0                      0   \n",
       "\n",
       "   Critical Risk_Vehicles and Mobile Equipment  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "\n",
       "   Critical Risk_Venomous Animals  Critical Risk_remains of choco  \n",
       "0                               0                               0  \n",
       "1                               0                               0  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nehag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nehag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# to use regular expressions for manipulating text data\n",
    "import re\n",
    "\n",
    "# to load the natural language toolkit\n",
    "import nltk\n",
    "nltk.download('stopwords')    # loading the stopwords\n",
    "nltk.download('wordnet')  \n",
    "\n",
    "# to remove common stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# to perform stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# to create Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To lowercase\n",
    "is_df['Description_T'] = is_df['Description'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-alphanumeric chars\n",
    "is_df['Description_T'] = is_df['Description_T'].apply(lambda x: ''.join(re.sub('[^A-Za-z0-9]+', ' ', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extra white spaces\n",
    "is_df['Description_T'] = is_df['Description_T'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword removal\n",
    "is_df['Description_T'] = is_df['Description_T'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Description_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "      <td>removing drill rod jumbo 08 maintenance superv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "      <td>activation sodium sulphide pump piping uncoupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "      <td>sub station milpo located level 170 collaborat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "      <td>9 45 approximately nv 1880 cx 695 ob7 personne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "      <td>approximately 11 45 circumstances mechanics an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>During the unloading operation of the ustulado...</td>\n",
       "      <td>unloading operation ustulado bag need unclog d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The collaborator reports that he was on street...</td>\n",
       "      <td>collaborator reports street 09 holding left ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>At approximately 04:50 p.m., when the mechanic...</td>\n",
       "      <td>approximately 04 50 p mechanic technician jos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Employee was sitting in the resting area at le...</td>\n",
       "      <td>employee sitting resting area level 326 raise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At the moment the forklift operator went to ma...</td>\n",
       "      <td>moment forklift operator went manipulate big b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>While installing a segment of the polyurethane...</td>\n",
       "      <td>installing segment polyurethane pulley protect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   While removing the drill rod of the Jumbo 08 f...   \n",
       "1   During the activation of a sodium sulphide pum...   \n",
       "2   In the sub-station MILPO located at level +170...   \n",
       "3   Being 9:45 am. approximately in the Nv. 1880 C...   \n",
       "4   Approximately at 11:45 a.m. in circumstances t...   \n",
       "5   During the unloading operation of the ustulado...   \n",
       "6   The collaborator reports that he was on street...   \n",
       "7   At approximately 04:50 p.m., when the mechanic...   \n",
       "8   Employee was sitting in the resting area at le...   \n",
       "9   At the moment the forklift operator went to ma...   \n",
       "10  While installing a segment of the polyurethane...   \n",
       "\n",
       "                                        Description_T  \n",
       "0   removing drill rod jumbo 08 maintenance superv...  \n",
       "1   activation sodium sulphide pump piping uncoupl...  \n",
       "2   sub station milpo located level 170 collaborat...  \n",
       "3   9 45 approximately nv 1880 cx 695 ob7 personne...  \n",
       "4   approximately 11 45 circumstances mechanics an...  \n",
       "5   unloading operation ustulado bag need unclog d...  \n",
       "6   collaborator reports street 09 holding left ha...  \n",
       "7   approximately 04 50 p mechanic technician jos ...  \n",
       "8   employee sitting resting area level 326 raise ...  \n",
       "9   moment forklift operator went manipulate big b...  \n",
       "10  installing segment polyurethane pulley protect...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df.loc[0:10, ['Description', 'Description_T']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nehag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "is_df['Description_WL'] = is_df.apply(lambda row: nltk.word_tokenize(row['Description_T']), axis=1)\n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "      new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return ' '.join(new_words)\n",
    "is_df['Description_WL'] = is_df.apply(lambda x: lemmatize_list(x['Description_WL']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Description_WL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "      <td>remove drill rod jumbo 08 maintenance supervis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "      <td>activation sodium sulphide pump pip uncouple s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "      <td>sub station milpo locate level 170 collaborato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "      <td>9 45 approximately nv 1880 cx 695 ob7 personne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "      <td>approximately 11 45 circumstances mechanics an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>During the unloading operation of the ustulado...</td>\n",
       "      <td>unload operation ustulado bag need unclog disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The collaborator reports that he was on street...</td>\n",
       "      <td>collaborator report street 09 hold leave hand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>At approximately 04:50 p.m., when the mechanic...</td>\n",
       "      <td>approximately 04 50 p mechanic technician jos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Employee was sitting in the resting area at le...</td>\n",
       "      <td>employee sit rest area level 326 raise bore su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At the moment the forklift operator went to ma...</td>\n",
       "      <td>moment forklift operator go manipulate big bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>While installing a segment of the polyurethane...</td>\n",
       "      <td>instal segment polyurethane pulley protective ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   While removing the drill rod of the Jumbo 08 f...   \n",
       "1   During the activation of a sodium sulphide pum...   \n",
       "2   In the sub-station MILPO located at level +170...   \n",
       "3   Being 9:45 am. approximately in the Nv. 1880 C...   \n",
       "4   Approximately at 11:45 a.m. in circumstances t...   \n",
       "5   During the unloading operation of the ustulado...   \n",
       "6   The collaborator reports that he was on street...   \n",
       "7   At approximately 04:50 p.m., when the mechanic...   \n",
       "8   Employee was sitting in the resting area at le...   \n",
       "9   At the moment the forklift operator went to ma...   \n",
       "10  While installing a segment of the polyurethane...   \n",
       "\n",
       "                                       Description_WL  \n",
       "0   remove drill rod jumbo 08 maintenance supervis...  \n",
       "1   activation sodium sulphide pump pip uncouple s...  \n",
       "2   sub station milpo locate level 170 collaborato...  \n",
       "3   9 45 approximately nv 1880 cx 695 ob7 personne...  \n",
       "4   approximately 11 45 circumstances mechanics an...  \n",
       "5   unload operation ustulado bag need unclog disc...  \n",
       "6   collaborator report street 09 hold leave hand ...  \n",
       "7   approximately 04 50 p mechanic technician jos ...  \n",
       "8   employee sit rest area level 326 raise bore su...  \n",
       "9   moment forklift operator go manipulate big bag...  \n",
       "10  instal segment polyurethane pulley protective ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df.loc[0:10, ['Description', 'Description_WL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=is_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m wv \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m vec_king \u001b[38;5;241m=\u001b[39m wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\downloader.py:503\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    501\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, BASE_DIR)\n\u001b[0;32m    502\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28m__import__\u001b[39m(name)\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32m~/gensim-data\\word2vec-google-news-300\\__init__.py:8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec-google-news-300.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(path, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39mfvocab, binary\u001b[38;5;241m=\u001b[39mbinary, encoding\u001b[38;5;241m=\u001b[39mencoding, unicode_errors\u001b[38;5;241m=\u001b[39municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit, datatype\u001b[38;5;241m=\u001b[39mdatatype, no_header\u001b[38;5;241m=\u001b[39mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2065\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2062\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(vector_size, vocab_size, dtype\u001b[38;5;241m=\u001b[39mdatatype)\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m-> 2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2069\u001b[0m     _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1960\u001b[0m, in \u001b[0;36m_word2vec_read_binary\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding)\u001b[0m\n\u001b[0;32m   1958\u001b[0m new_chunk \u001b[38;5;241m=\u001b[39m fin\u001b[38;5;241m.\u001b[39mread(binary_chunk_size)\n\u001b[0;32m   1959\u001b[0m chunk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_chunk\n\u001b[1;32m-> 1960\u001b[0m processed_words, chunk \u001b[38;5;241m=\u001b[39m _add_bytes_to_kv(\n\u001b[0;32m   1961\u001b[0m     kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors, encoding)\n\u001b[0;32m   1962\u001b[0m tot_processed_words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m processed_words\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_chunk) \u001b[38;5;241m<\u001b[39m binary_chunk_size:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1942\u001b[0m, in \u001b[0;36m_add_bytes_to_kv\u001b[1;34m(kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;66;03m# Some binary files are reported to have obsolete new line in the beginning of word, remove it\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m word \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1942\u001b[0m vector \u001b[38;5;241m=\u001b[39m frombuffer(chunk, offset\u001b[38;5;241m=\u001b[39mi_vector, count\u001b[38;5;241m=\u001b[39mvector_size, dtype\u001b[38;5;241m=\u001b[39mREAL)\u001b[38;5;241m.\u001b[39mastype(datatype)\n\u001b[0;32m   1943\u001b[0m _add_word_to_kv(kv, counts, word, vector, vocab_size)\n\u001b[0;32m   1944\u001b[0m start \u001b[38;5;241m=\u001b[39m i_vector \u001b[38;5;241m+\u001b[39m bytes_per_vector\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2626)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>001</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>018</th>\n",
       "      <th>0183</th>\n",
       "      <th>02</th>\n",
       "      <th>020</th>\n",
       "      <th>02bp0166</th>\n",
       "      <th>02bp0167</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>z014</th>\n",
       "      <th>zaf</th>\n",
       "      <th>zamac</th>\n",
       "      <th>zaro</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zinco</th>\n",
       "      <th>zn</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  001  007  01  018  0183  02  020  02bp0166  02bp0167  ...  young  z014  \\\n",
       "0   0    0    0   0    0     0   0    0         0         0  ...      0     0   \n",
       "1   0    0    0   0    0     0   0    0         0         0  ...      0     0   \n",
       "2   0    0    0   0    0     0   0    0         0         0  ...      0     0   \n",
       "3   0    0    0   0    0     0   0    0         0         0  ...      0     0   \n",
       "4   0    0    0   0    0     0   0    0         0         0  ...      0     0   \n",
       "\n",
       "   zaf  zamac  zaro  zero  zinc  zinco  zn  zone  \n",
       "0    0      0     0     0     0      0   0     0  \n",
       "1    0      0     0     0     0      0   0     0  \n",
       "2    0      0     0     0     0      0   0     0  \n",
       "3    0      0     0     0     0      0   0     0  \n",
       "4    1      0     0     0     0      0   0     0  \n",
       "\n",
       "[5 rows x 2626 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Ticket Data\n",
    "corpus = df['Description_WL'].values\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "#print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 2626)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsVocab=CountVectorizedData.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00', '001', '007', '01', '018', '0183', '02', '020', '02bp0166',\n",
       "       '02bp0167',\n",
       "       ...\n",
       "       'young', 'z014', 'zaf', 'zamac', 'zaro', 'zero', 'zinc', 'zinco', 'zn',\n",
       "       'zone'],\n",
       "      dtype='object', length=2626)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordsVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionText2Vec(inpTextData):\n",
    "    # Converting the text to numeric data\n",
    "    X = vectorizer.transform(inpTextData)\n",
    "    CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "    W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "    # Looping through each row for the data\n",
    "    for i in range(CountVecData.shape[0]):\n",
    " \n",
    "        # initiating a sentence with all zeros\n",
    "        Sentence = np.zeros(300)\n",
    " \n",
    "        # Looping thru each word in the sentence and if its present in \n",
    "        # the Word2Vec model then storing its vector\n",
    "        for word in WordsVocab[CountVecData.iloc[i , :]>=1]:\n",
    "            #print(word)\n",
    "            if word in wv.key_to_index.keys():    \n",
    "                Sentence=Sentence+wv[word]\n",
    "        # Appending the sentence to the dataframe\n",
    "        W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence], columns=['Word2vec_'+str(i) for i in range(300)]))\n",
    "    return(W2Vec_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 300)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vec_Data=FunctionText2Vec(df['Description_WL'])\n",
    " \n",
    "# Checking the new representation for sentences\n",
    "W2Vec_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word2vec_0</th>\n",
       "      <th>Word2vec_1</th>\n",
       "      <th>Word2vec_2</th>\n",
       "      <th>Word2vec_3</th>\n",
       "      <th>Word2vec_4</th>\n",
       "      <th>Word2vec_5</th>\n",
       "      <th>Word2vec_6</th>\n",
       "      <th>Word2vec_7</th>\n",
       "      <th>Word2vec_8</th>\n",
       "      <th>Word2vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Word2vec_290</th>\n",
       "      <th>Word2vec_291</th>\n",
       "      <th>Word2vec_292</th>\n",
       "      <th>Word2vec_293</th>\n",
       "      <th>Word2vec_294</th>\n",
       "      <th>Word2vec_295</th>\n",
       "      <th>Word2vec_296</th>\n",
       "      <th>Word2vec_297</th>\n",
       "      <th>Word2vec_298</th>\n",
       "      <th>Word2vec_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.3971</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>-0.5375</td>\n",
       "      <td>1.2903</td>\n",
       "      <td>-5.2409</td>\n",
       "      <td>-0.8309</td>\n",
       "      <td>1.2430</td>\n",
       "      <td>-2.1095</td>\n",
       "      <td>2.5383</td>\n",
       "      <td>-0.2788</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.7982</td>\n",
       "      <td>1.8420</td>\n",
       "      <td>-1.6566</td>\n",
       "      <td>-0.0958</td>\n",
       "      <td>-0.3956</td>\n",
       "      <td>-0.6332</td>\n",
       "      <td>-0.6710</td>\n",
       "      <td>-0.2596</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>-1.4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.3691</td>\n",
       "      <td>-0.6511</td>\n",
       "      <td>-0.0432</td>\n",
       "      <td>1.5873</td>\n",
       "      <td>-2.2016</td>\n",
       "      <td>1.9080</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>-3.3161</td>\n",
       "      <td>1.9831</td>\n",
       "      <td>1.8557</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0042</td>\n",
       "      <td>-0.5540</td>\n",
       "      <td>-0.9723</td>\n",
       "      <td>-0.3482</td>\n",
       "      <td>-1.3102</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>-1.1423</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>2.3805</td>\n",
       "      <td>-1.2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0287</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>-0.4457</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>-2.7438</td>\n",
       "      <td>1.0511</td>\n",
       "      <td>1.5532</td>\n",
       "      <td>-3.1565</td>\n",
       "      <td>2.8371</td>\n",
       "      <td>2.0244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8700</td>\n",
       "      <td>1.7216</td>\n",
       "      <td>-2.3878</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>-0.1223</td>\n",
       "      <td>-0.4100</td>\n",
       "      <td>-1.0255</td>\n",
       "      <td>-0.5229</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>-1.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0015</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>-0.3741</td>\n",
       "      <td>1.3097</td>\n",
       "      <td>-4.6205</td>\n",
       "      <td>-0.5167</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>-4.0824</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2804</td>\n",
       "      <td>4.6677</td>\n",
       "      <td>-3.4970</td>\n",
       "      <td>-0.7187</td>\n",
       "      <td>-2.1707</td>\n",
       "      <td>-1.3932</td>\n",
       "      <td>0.5741</td>\n",
       "      <td>-1.2822</td>\n",
       "      <td>0.3647</td>\n",
       "      <td>0.4959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5436</td>\n",
       "      <td>2.5934</td>\n",
       "      <td>-0.6664</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>-2.3422</td>\n",
       "      <td>-1.2845</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>-3.0798</td>\n",
       "      <td>3.4993</td>\n",
       "      <td>1.3562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4532</td>\n",
       "      <td>3.4847</td>\n",
       "      <td>-3.7164</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.9616</td>\n",
       "      <td>-0.6076</td>\n",
       "      <td>-2.2227</td>\n",
       "      <td>-0.4572</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>-1.9005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word2vec_0  Word2vec_1  Word2vec_2  Word2vec_3  Word2vec_4  Word2vec_5  \\\n",
       "0     -2.3971      0.5704     -0.5375      1.2903     -5.2409     -0.8309   \n",
       "0     -1.3691     -0.6511     -0.0432      1.5873     -2.2016      1.9080   \n",
       "0      0.0287      1.1200     -0.4457      0.9456     -2.7438      1.0511   \n",
       "0     -0.0015      0.2424     -0.3741      1.3097     -4.6205     -0.5167   \n",
       "0     -0.5436      2.5934     -0.6664      0.7800     -2.3422     -1.2845   \n",
       "\n",
       "   Word2vec_6  Word2vec_7  Word2vec_8  Word2vec_9  ...  Word2vec_290  \\\n",
       "0      1.2430     -2.1095      2.5383     -0.2788  ...       -1.7982   \n",
       "0     -0.3743     -3.3161      1.9831      1.8557  ...       -1.0042   \n",
       "0      1.5532     -3.1565      2.8371      2.0244  ...       -0.8700   \n",
       "0      0.9587     -4.0824      2.9199      0.8226  ...       -1.2804   \n",
       "0      1.1223     -3.0798      3.4993      1.3562  ...       -0.4532   \n",
       "\n",
       "   Word2vec_291  Word2vec_292  Word2vec_293  Word2vec_294  Word2vec_295  \\\n",
       "0        1.8420       -1.6566       -0.0958       -0.3956       -0.6332   \n",
       "0       -0.5540       -0.9723       -0.3482       -1.3102        0.8795   \n",
       "0        1.7216       -2.3878        0.5889       -0.1223       -0.4100   \n",
       "0        4.6677       -3.4970       -0.7187       -2.1707       -1.3932   \n",
       "0        3.4847       -3.7164        0.0333       -0.9616       -0.6076   \n",
       "\n",
       "   Word2vec_296  Word2vec_297  Word2vec_298  Word2vec_299  \n",
       "0       -0.6710       -0.2596       -0.2548       -1.4445  \n",
       "0       -1.1423        0.6014        2.3805       -1.2493  \n",
       "0       -1.0255       -0.5229        0.1519       -1.1768  \n",
       "0        0.5741       -1.2822        0.3647        0.4959  \n",
       "0       -2.2227       -0.4572        0.1055       -1.9005  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vec_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset= is_df.join(W2Vec_Data.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.drop(['Description','Description_T','Description_WL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Level</th>\n",
       "      <th>Potential Accident Level</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country_Country_01</th>\n",
       "      <th>Country_Country_02</th>\n",
       "      <th>Country_Country_03</th>\n",
       "      <th>Local_Local_01</th>\n",
       "      <th>Local_Local_02</th>\n",
       "      <th>Local_Local_03</th>\n",
       "      <th>Local_Local_04</th>\n",
       "      <th>...</th>\n",
       "      <th>Word2vec_290</th>\n",
       "      <th>Word2vec_291</th>\n",
       "      <th>Word2vec_292</th>\n",
       "      <th>Word2vec_293</th>\n",
       "      <th>Word2vec_294</th>\n",
       "      <th>Word2vec_295</th>\n",
       "      <th>Word2vec_296</th>\n",
       "      <th>Word2vec_297</th>\n",
       "      <th>Word2vec_298</th>\n",
       "      <th>Word2vec_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.7982</td>\n",
       "      <td>1.8420</td>\n",
       "      <td>-1.6566</td>\n",
       "      <td>-0.0958</td>\n",
       "      <td>-0.3956</td>\n",
       "      <td>-0.6332</td>\n",
       "      <td>-0.6710</td>\n",
       "      <td>-0.2596</td>\n",
       "      <td>-0.2548</td>\n",
       "      <td>-1.4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0042</td>\n",
       "      <td>-0.5540</td>\n",
       "      <td>-0.9723</td>\n",
       "      <td>-0.3482</td>\n",
       "      <td>-1.3102</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>-1.1423</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>2.3805</td>\n",
       "      <td>-1.2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8700</td>\n",
       "      <td>1.7216</td>\n",
       "      <td>-2.3878</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>-0.1223</td>\n",
       "      <td>-0.4100</td>\n",
       "      <td>-1.0255</td>\n",
       "      <td>-0.5229</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>-1.1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.2804</td>\n",
       "      <td>4.6677</td>\n",
       "      <td>-3.4970</td>\n",
       "      <td>-0.7187</td>\n",
       "      <td>-2.1707</td>\n",
       "      <td>-1.3932</td>\n",
       "      <td>0.5741</td>\n",
       "      <td>-1.2822</td>\n",
       "      <td>0.3647</td>\n",
       "      <td>0.4959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4532</td>\n",
       "      <td>3.4847</td>\n",
       "      <td>-3.7164</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.9616</td>\n",
       "      <td>-0.6076</td>\n",
       "      <td>-2.2227</td>\n",
       "      <td>-0.4572</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>-1.9005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 357 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accident Level  Potential Accident Level  Gender  Country_Country_01  \\\n",
       "0               1                         4       0                   1   \n",
       "1               1                         4       0                   0   \n",
       "2               1                         3       0                   1   \n",
       "3               1                         1       0                   1   \n",
       "4               4                         4       0                   1   \n",
       "\n",
       "   Country_Country_02  Country_Country_03  Local_Local_01  Local_Local_02  \\\n",
       "0                   0                   0               1               0   \n",
       "1                   1                   0               0               1   \n",
       "2                   0                   0               0               0   \n",
       "3                   0                   0               0               0   \n",
       "4                   0                   0               0               0   \n",
       "\n",
       "   Local_Local_03  Local_Local_04  ...  Word2vec_290  Word2vec_291  \\\n",
       "0               0               0  ...       -1.7982        1.8420   \n",
       "1               0               0  ...       -1.0042       -0.5540   \n",
       "2               1               0  ...       -0.8700        1.7216   \n",
       "3               0               1  ...       -1.2804        4.6677   \n",
       "4               0               1  ...       -0.4532        3.4847   \n",
       "\n",
       "   Word2vec_292  Word2vec_293  Word2vec_294  Word2vec_295  Word2vec_296  \\\n",
       "0       -1.6566       -0.0958       -0.3956       -0.6332       -0.6710   \n",
       "1       -0.9723       -0.3482       -1.3102        0.8795       -1.1423   \n",
       "2       -2.3878        0.5889       -0.1223       -0.4100       -1.0255   \n",
       "3       -3.4970       -0.7187       -2.1707       -1.3932        0.5741   \n",
       "4       -3.7164        0.0333       -0.9616       -0.6076       -2.2227   \n",
       "\n",
       "   Word2vec_297  Word2vec_298  Word2vec_299  \n",
       "0       -0.2596       -0.2548       -1.4445  \n",
       "1        0.6014        2.3805       -1.2493  \n",
       "2       -0.5229        0.1519       -1.1768  \n",
       "3       -1.2822        0.3647        0.4959  \n",
       "4       -0.4572        0.1055       -1.9005  \n",
       "\n",
       "[5 rows x 357 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"nlp_chatbot_word2vec.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_df = pd.DataFrame()\n",
    "for i in [1,2]:\n",
    "    tfidf = TfidfVectorizer(max_features=50, stop_words='english',use_idf=True, ngram_range=(i,i))\n",
    "    X = tfidf.fit_transform(is_df['Description_WL']).toarray()\n",
    "    tfs = pd.DataFrame(X, columns=[\"TFIDF_\" + n for n in tfidf.get_feature_names_out()])\n",
    "    tfidf_df = pd.concat([tfidf_df.reset_index(drop=True), tfs.reset_index(drop=True)], axis=1)\n",
    "\n",
    "tfidf_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset= is_df.join(tfidf_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.drop(['Description','Description_T','Description_WL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.to_csv(\"nlp_chatbot_TF_IDF.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
